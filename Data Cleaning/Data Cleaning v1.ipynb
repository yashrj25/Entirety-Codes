{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "matched-grass",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dateutil\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import regex as re\n",
    "import datetime\n",
    "import calendar\n",
    "from dateutil.relativedelta import relativedelta, TH\n",
    "from dateutil.parser import parse\n",
    "import holidays as h\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "pd.set_option('display.max_rows', 5000)\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "\n",
    "holidays = h.get_holidays()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forbidden-holder",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = pd.DataFrame(glob('/Users/entirety/Documents/Entirety - AMC/Data/Raw Market Data/nfo_2019-20_raw/*'), columns=['location'])\n",
    "all_files['data_date'] = all_files['location'].apply(lambda x: x.split('_')[-1].split('.')[0])\n",
    "all_files['data_date'] = all_files['data_date'].apply(lambda x: datetime.datetime.strptime(x.strip(),'%d%m%Y').date())\n",
    "all_files.sort_values('data_date',inplace=True)\n",
    "all_files.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suitable-connecticut",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = pd.DataFrame(glob('/Users/entirety/Downloads/data/*'), columns=['location'])\n",
    "all_files['data_date'] = all_files['location'].apply(lambda x: x.split('_')[-1].split('.')[0])\n",
    "all_files['data_date'] = all_files['data_date'].apply(lambda x: datetime.datetime.strptime(x.strip(),'%d%m%Y').date())\n",
    "all_files.sort_values('data_date',inplace=True)\n",
    "all_files.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-visiting",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "injured-requirement",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def get_nearest_expiry(date, month_offset):\n",
    "\n",
    "    year = date.year\n",
    "    month = date.month + month_offset\n",
    "    day = date.day\n",
    "\n",
    "    if month > 12:\n",
    "        month = month-12\n",
    "        year = year+1\n",
    "\n",
    "    last_day_of_the_month = datetime.date(year, month, calendar.monthrange(year, month)[1])\n",
    "    last_thursday_of_the_month = last_day_of_the_month + relativedelta(weekday=TH(-1))\n",
    "\n",
    "    if date <= last_thursday_of_the_month:\n",
    "        nearest_expiry = last_thursday_of_the_month\n",
    "\n",
    "    elif date > last_thursday_of_the_month:\n",
    "        if (month+1) <= 12:\n",
    "            last_day_of_the_next_month = datetime.date(\n",
    "                year, month+1, calendar.monthrange(year, month+1)[1])\n",
    "            last_thursday_of_the_next_month = last_day_of_the_next_month + \\\n",
    "                relativedelta(weekday=TH(-1))\n",
    "            nearest_expiry = last_thursday_of_the_next_month\n",
    "        else:\n",
    "            last_day_of_the_next_month = datetime.date(year, 1, calendar.monthrange(year, 1)[1])\n",
    "            last_thursday_of_the_next_month = last_day_of_the_next_month + \\\n",
    "                relativedelta(weekday=TH(-1))\n",
    "            nearest_expiry = last_thursday_of_the_next_month\n",
    "\n",
    "    while True:\n",
    "        \n",
    "        if nearest_expiry in holidays:\n",
    "            nearest_expiry = nearest_expiry - datetime.timedelta(days=1)\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return nearest_expiry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pregnant-field",
   "metadata": {
    "code_folding": [
     41
    ]
   },
   "outputs": [],
   "source": [
    "def get_instrument_params(x):\n",
    "    \n",
    "    day = None\n",
    "    nearest_expiry = None\n",
    "    data_date = x['date']\n",
    "    ticker = x['ticker']\n",
    "    flag = 0\n",
    "    month_offsets = {'I':0,'II':1,'III':2}\n",
    "\n",
    "    try:\n",
    "        try:\n",
    "            #ACC-III, BAJAJ-AUTO-I, L&TFH-I, M&M-I, S&P500-I\n",
    "            temp = re.findall(r'([A-Z]{1,10}&[A-Z]{1,10}|[A-Z]{1,10}-[A-Z]{1,10}|[A-Z]{1,10}[0-9]{1,2}[A-Z]{1,10}|[A-Z]{1,10}|[A-Z]{1,10}&[A-Z]{1,10}[0-9]{1,3}|[A-Z]{1,9}[0-9]{1,3})(-)([I]{1,3})',ticker)[0]\n",
    "            instrument_name, expiry_type = temp[0],temp[-1]\n",
    "            instrument_type = 'FUT'\n",
    "            flag = 1\n",
    "            strike_price = np.NaN\n",
    "\n",
    "        except:\n",
    "            try:\n",
    "                #ACC19FEB1240PE\n",
    "                instrument_name, year, month, strike_price, instrument_type = re.findall(r'([A-Z]{1,10}&[A-Z]{1,10}|[A-Z]{1,10}-[A-Z]{1,10}|[A-Z]{1,10}[0-9]{1,2}[A-Z]{1,10}|[A-Z]{1,10})(17|18|19|20|21)(JAN|FEB|MAR|APR|MAY|JUN|JUL|AUG|SEP|OCT|NOV|DEC)([0-9]{1,5})(CE|PE)',ticker)[0]\n",
    "                expiry_type = None\n",
    "\n",
    "            except:\n",
    "                try:\n",
    "                    #ACC24SEP201000CE\n",
    "                    instrument_name, day, month, year, strike_price, instrument_type = re.findall(r'([A-Z]{1,10}&[A-Z]{1,10}|[A-Z]{1,10}-[A-Z]{1,10}|[A-Z]{1,10}[0-9]{1,2}[A-Z]{1,10}|[A-Z]{1,10})([0-9]{2})(JAN|FEB|MAR|APR|MAY|JUN|JUL|AUG|SEP|OCT|NOV|DEC)(17|18|19|20|21)([0-9]{1,5})(CE|PE)',ticker)[0]\n",
    "                    expiry_type = None\n",
    "\n",
    "                except:\n",
    "                    try:\n",
    "                        #NIFTY19DECCE10000\n",
    "                        instrument_name, year, month, instrument_type, strike_price = re.findall(r'([A-Z]{1,10}&[A-Z]{1,10}|[A-Z]{1,10}-[A-Z]{1,10}|[A-Z]{1,10}[0-9]{1,2}[A-Z]{1,10}|[A-Z]{1,10})(17|18|19|20|21)(JAN|FEB|MAR|APR|MAY|JUN|JUL|AUG|SEP|OCT|NOV|DEC)(CE|PE)([0-9]{1,5})',ticker)[0]\n",
    "                        expiry_type = None\n",
    "\n",
    "                    except:\n",
    "                        try:\n",
    "                            #NIFTY27JUN2411500PE\n",
    "                            instrument_name, day, month, year, strike_price, instrument_type = re.findall(r'(NIFTY|BANKNIFTY)([0-9]{2})(JAN|FEB|MAR|APR|MAY|JUN|JUL|AUG|SEP|OCT|NOV|DEC)(22|23|24)([0-9]{1,5})(CE|PE)',ticker)[0] \n",
    "                            expiry_type = None\n",
    "\n",
    "                        except:\n",
    "                            try:\n",
    "                                #OPTIDX_NIFTY_25JUN2020_CE_10000\n",
    "                                instrument_name, day, month, year, instrument_type, strike_price = re.findall(r'(NIFTY|BANKNIFTY)_([0-9]{2})(JAN|FEB|MAR|APR|MAY|JUN|JUL|AUG|SEP|OCT|NOV|DEC)(2019|2020|2021)_(CE|PE)_([0-9]{1,5})',ticker)[0]\n",
    "                                expiry_type = None\n",
    "                                year = year[-2:]\n",
    "\n",
    "                            except:\n",
    "                                try:\n",
    "                                    #TORNTPOWER19AUGFUT\n",
    "                                    instrument_name,year,month,instrument_type = re.findall(r'([A-Z]{3,12})(19|20)(JAN|FEB|MAR|APR|MAY|JUN|JUL|AUG|SEP|OCT|NOV|DEC)(FUT)',ticker)[0]\n",
    "                                    expiry_type = None\n",
    "                                    strike_price = np.NaN\n",
    "\n",
    "                                except:\n",
    "                                    try:\n",
    "                                        #----------------------------------------------------------------------------\n",
    "                                        #ADANIENT25JUN20137 this one not required hence fill the values with na later\n",
    "                                        ticker = re.findall(r'([A-Z]{1,10}&[A-Z]{1,10}|[A-Z]{1,10}-[A-Z]{1,10}|[A-Z]{1,10}[0-9]{1,2}[A-Z]{1,10}|[A-Z]{1,10})([0-9]{2})(JAN|FEB|MAR|APR|MAY|JUN|JUL|AUG|SEP|OCT|NOV|DEC)(17|18|19|20|21)([0-9]{1,5})',ticker)[0]\n",
    "                                        strike_price = np.NaN\n",
    "                                        instrument_type = np.NaN\n",
    "                                        nearest_expiry = np.NaN\n",
    "                                        instrument_name = np.NaN\n",
    "                                        expiry_type = np.NaN  \n",
    "\n",
    "                                    except:\n",
    "                                        try:\n",
    "                                            #----------------------------------------------------------------------------\n",
    "                                            #ADANIPOWER19JAN57 this one not required hence fill the values with na later\n",
    "                                            ticker = re.findall(r'([A-Z]{1,10}&[A-Z]{1,10}|[A-Z]{1,10}-[A-Z]{1,10}|[A-Z]{1,10}[0-9]{1,2}[A-Z]{1,10}|[A-Z]{1,10})(17|18|19|20|21)(JAN|FEB|MAR|APR|MAY|JUN|JUL|AUG|SEP|OCT|NOV|DEC)([0-9]{1,5})',ticker)[0]\n",
    "                                            strike_price = np.NaN\n",
    "                                            instrument_type = np.NaN\n",
    "                                            nearest_expiry = np.NaN\n",
    "                                            instrument_name = np.NaN\n",
    "                                            expiry_type = np.NaN\n",
    "                                        except:\n",
    "                                            ticker = np.NaN\n",
    "                                            strike_price = np.NaN\n",
    "                                            instrument_type = np.NaN\n",
    "                                            nearest_expiry = np.NaN\n",
    "                                            instrument_name = np.NaN\n",
    "                                            expiry_type = np.NaN\n",
    "\n",
    "        #options expiry computation\n",
    "        if (day == None) & (nearest_expiry == None) & (flag == 0):\n",
    "            year = int(year)\n",
    "            month = datetime.datetime.strptime(month,'%b').month\n",
    "            nearest_expiry = datetime.date(year,month,calendar.monthrange(year, month)[1]) + relativedelta(weekday=TH(-1))\n",
    "            nearest_expiry = datetime.datetime.strptime(str(nearest_expiry),'00%y-%m-%d').date()\n",
    "            while True:\n",
    "                if nearest_expiry in holidays:\n",
    "                    nearest_expiry = nearest_expiry - datetime.timedelta(days = 1)\n",
    "                    continue\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "        #banknifty/nifty weekly options expiry computation\n",
    "        elif (day != None) & (nearest_expiry == None) & ((instrument_type == 'CE') or (instrument_type == 'PE')):\n",
    "            nearest_expiry = datetime.datetime.strptime(day+month+year,'%d%b%y').date()\n",
    "\n",
    "        #futures expiry computation\n",
    "        elif (day == None) & (nearest_expiry == None) & (instrument_type == 'FUT'):\n",
    "            nearest_expiry = get_nearest_expiry(data_date,month_offsets[expiry_type])\n",
    "\n",
    "        return strike_price, instrument_type, nearest_expiry, instrument_name, expiry_type\n",
    "    except:\n",
    "        print('Error in: ',ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grateful-politics",
   "metadata": {},
   "outputs": [],
   "source": [
    "eliminated_files = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "large-arbor",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "print(datetime.datetime.now().time())\n",
    "\n",
    "for index, row in all_files.iterrows():\n",
    "    \n",
    "    print(index)\n",
    "    try:\n",
    "    \n",
    "        data = pd.read_csv(row['location'])\n",
    "        data.columns = data.columns.str.lower()\n",
    "        data.columns = data.columns.str.strip()\n",
    "        data.columns = data.columns.str.replace(' ', '_')\n",
    "\n",
    "        try:\n",
    "            data['time'] = data['time'].apply(lambda x: x.strip())\n",
    "        except:\n",
    "            data['time'] = data['time'].apply(lambda x: str(x).strip())\n",
    "\n",
    "        try:\n",
    "            data['date'] = data['date'].apply(lambda x: x.strip())\n",
    "        except:\n",
    "            data['date'] = data['date'].apply(lambda x: str(x).strip())\n",
    "\n",
    "\n",
    "        data = data.rename(columns={'openinterest':'open_interest'})\n",
    "        data = data.rename(columns={'opne_interest':'open_interest'})\n",
    "        data = data.rename(columns={'dtae':'date'})\n",
    "        data = data.rename(columns={'higgh':'high'})\n",
    "\n",
    "        data = data[['ticker', 'date', 'time', 'open', 'high', 'low', 'close', 'volume', 'open_interest']]\n",
    "\n",
    "        try:\n",
    "            data['date'] = data['date'].apply(lambda x: datetime.datetime.strptime(x,'%d/%m/%Y').date())\n",
    "        except:\n",
    "            try:\n",
    "                data['date'] = data['date'].apply(lambda x: datetime.datetime.strptime(x,'%d-%m-%Y').date())\n",
    "            except:        \n",
    "                try:\n",
    "                    data['date'] = data['date'].apply(lambda x: datetime.datetime.strptime(x,'%d/%m/%Y').date() if x!='nan' else np.NaN)\n",
    "                except:\n",
    "                    data['time'] = np.where(data['time'] == '#VALUE!', data['date'].apply(lambda x: x.split(' ')[-1]),data['time'])\n",
    "                    data['date'] = data['date'].apply(lambda x: x.split(' ')[0])\n",
    "                    data['date'] = data['date'].apply(lambda x: datetime.datetime.strptime(x,'%d/%m/%Y').date())\n",
    "\n",
    "        try:\n",
    "            data['time'] = data['time'].apply(lambda x: datetime.datetime.strptime(x,'%H:%M:%S').time().replace(second=0, microsecond=0))\n",
    "        except:\n",
    "            try:\n",
    "                data['time'] = data['time'].apply(lambda x: datetime.datetime.strptime(x,'%H:%M:%S').time().replace(second=0, microsecond=0) if x!='nan' else np.NaN)\n",
    "            except:\n",
    "                data['time'] = data['time'].apply(lambda x: datetime.datetime.strptime(x,'%H:%M:%S').time().replace(second=0, microsecond=0) if len(x)>5 else datetime.datetime.strptime(str(x)+':00','%H:%M:%S').time().replace(second=0, microsecond=0))\n",
    "\n",
    "        try:\n",
    "            data['datetime'] = data[['date','time']].apply(lambda x: datetime.datetime.combine(x['date'],x['time']),axis=1)\n",
    "        except:\n",
    "            try:\n",
    "                data['datetime'] = data[['date','time']].apply(lambda x: datetime.datetime.combine(x['date'],x['time']) if ((x['date']!='nan') and (x['time']!='nan')) else np.NaN,axis=1)\n",
    "            except:\n",
    "                data = data.dropna(subset=['time'])\n",
    "                data['datetime'] = data[['date','time']].apply(lambda x: datetime.datetime.combine(x['date'],x['time']),axis=1)\n",
    "\n",
    "        data['open'] = data['open'].astype('float')\n",
    "        data['high'] = data['high'].astype('float')\n",
    "        data['low'] = data['low'].astype('float')\n",
    "        data['close'] = data['close'].astype('float')\n",
    "        data['volume'] = data['volume'].astype('int')\n",
    "        data['open_interest'] = data['open_interest'].astype('int')\n",
    "        data['ticker'] = data['ticker'].apply(lambda x: (x.strip()).split('.')[0])\n",
    "\n",
    "        data['temp'] = data.apply(get_instrument_params,axis=1)\n",
    "        data['strike_price'] = data['temp'].apply(lambda x: x[0])\n",
    "        data['instrument_type'] = data['temp'].apply(lambda x: x[1])\n",
    "        data['expiry_date'] = data['temp'].apply(lambda x: x[2])\n",
    "        data['instrument_name'] = data['temp'].apply(lambda x: x[3])\n",
    "        data['expiry_type'] = data['temp'].apply(lambda x: x[4])\n",
    "        data = data[['ticker', 'datetime', 'date', 'time', 'open', 'high', 'low', 'close', 'volume', 'open_interest', 'strike_price', 'instrument_type', 'expiry_date', 'instrument_name', 'expiry_type']]\n",
    "        data['strike_price'] = data['strike_price'].apply(float)\n",
    "\n",
    "        data = data.dropna(subset=['instrument_name'])\n",
    "#         data.to_parquet(f\"/Users/entirety/Documents/Entirety - AMC/Data/variable_nfo_data_2016-21/all_instruments_nfo_data_{row['data_date']}.parquet\")\n",
    "        data.to_parquet(f\"/Users/entirety/Downloads/data/all_instruments_nfo_data_{row['data_date']}.parquet\")\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(row['location'])\n",
    "        eliminated_files.append(row['location'])\n",
    "\n",
    "print(datetime.datetime.now().time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "small-outline",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_parquet(f\"/Users/entirety/Documents/Entirety-AMC/Data/variable_nfo_data_2016-21/all_instruments_nfo_data_{row['data_date']}.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seasonal-footwear",
   "metadata": {},
   "source": [
    "### FIRST UNDERSTAND THIS BELOW CELL ðŸ‘‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supported-statement",
   "metadata": {
    "code_folding": [
     2
    ]
   },
   "outputs": [],
   "source": [
    "# regex_checker_data = pd.DataFrame(columns=['ticker','data_date'])\n",
    "\n",
    "# for index, row in all_files.iterrows():\n",
    "    \n",
    "#     print(index)\n",
    "#     data = pd.read_csv(row['location'])\n",
    "#     data.columns = data.columns.str.lower()\n",
    "#     data.columns = data.columns.str.strip()\n",
    "\n",
    "#     data = pd.DataFrame(data['ticker'].drop_duplicates(keep='first'))\n",
    "\n",
    "#     data['data_date'] = row['data_date']\n",
    "\n",
    "#     regex_checker_data = pd.concat([regex_checker_data[['ticker','data_date']],data[['ticker','data_date']]],axis=0)\n",
    "\n",
    "#     regex_checker_data = regex_checker_data.drop_duplicates(subset='ticker',keep=\"first\")\n",
    "\n",
    "# regex_checker_data.columns = ['ticker', 'date']\n",
    "# regex_checker_data['ticker'] = regex_checker_data['ticker'].apply(lambda x: str(x).split('.')[0])\n",
    "# regex_checker_data = regex_checker_data.drop_duplicates(subset='ticker',keep=\"first\")\n",
    "\n",
    "# regex_checker_data.sort_values('ticker',inplace=True)\n",
    "# regex_checker_data.reset_index(drop=True, inplace=True)\n",
    "# regex_checker_data = regex_checker_data[:-1]\n",
    "\n",
    "# regex_checker_data['temp'] = regex_checker_data.apply(get_instrument_params,axis=1)\n",
    "\n",
    "# regex_checker_data['strike_price'] = regex_checker_data['temp'].apply(lambda x: x[0])\n",
    "# regex_checker_data['instrument_type'] = regex_checker_data['temp'].apply(lambda x: x[1])\n",
    "# regex_checker_data['expiry_date'] = regex_checker_data['temp'].apply(lambda x: x[2])\n",
    "# regex_checker_data['instrument_name'] = regex_checker_data['temp'].apply(lambda x: x[3])\n",
    "# regex_checker_data['expiry_type'] = regex_checker_data['temp'].apply(lambda x: x[4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
